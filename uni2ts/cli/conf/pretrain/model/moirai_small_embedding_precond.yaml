# Moirai Small with Embedding-Level Preconditioning
#
# Applies polynomial preconditioning to patch embeddings inside the model forward pass.
# This operates after the patch projection layer (in_proj).
#
# Following Universal Sequence Preconditioning theory:
# - Only target variates (y_t) are preconditioned
# - Covariate variates (u_t) are left unchanged
# - Reversal after transformer is DISABLED (not a true inverse due to non-linear mixing)

_target_: uni2ts.model.moirai.MoiraiPretrain
module_kwargs:
  _target_: builtins.dict
  distr_output:
    _target_: uni2ts.distribution.MixtureOutput
    components:
      - _target_: uni2ts.distribution.StudentTOutput
      - _target_: uni2ts.distribution.NormalFixedScaleOutput
      - _target_: uni2ts.distribution.NegativeBinomialOutput
      - _target_: uni2ts.distribution.LogNormalOutput
  d_model: 384
  num_layers: 6
  patch_sizes: ${as_tuple:[8, 16, 32, 64, 128]}
  max_seq_len: 512
  attn_dropout_p: 0.0
  dropout_p: 0.0
  scaling: true
  # Embedding-level preconditioning configuration
  enable_embedding_preconditioning: true
  embedding_precondition_type: chebyshev
  embedding_precondition_degree: 5
  embedding_precondition_reverse: false  # DISABLED: Reversal after transformer is not a true inverse
  # Target variate filtering: only precondition first N variates (targets)
  # Set to null to precondition all variates (default for LOTSA pretraining)
  # Set to specific value (e.g., 1) to only precondition target and leave covariates unchanged
  num_target_variates: null

min_patches: 2
min_mask_ratio: 0.15
max_mask_ratio: 0.5
max_dim: 128
loss_func:
  _target_: uni2ts.loss.packed.PackedNLLLoss
lr: 1e-3
weight_decay: 1e-1
beta1: 0.9
beta2: 0.98
num_training_steps: ${mul:${trainer.max_epochs},${train_dataloader.num_batches_per_epoch}}
num_warmup_steps: 10_000

# Disable data-level preconditioning (we're using embedding-level instead)
enable_preconditioning: false
precondition_type: chebyshev
precondition_degree: 5
loss_in_original_space: false
learnable_preconditioning: false
