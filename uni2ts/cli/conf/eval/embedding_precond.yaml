# Hydra config for eval_embedding_precond.py
#
# Evaluates models trained with embedding-level preconditioning.
# The preconditioning happens inside the model, so no special data handling needed.

defaults:
  - _self_
  - data: monash_cached

# Checkpoint and model parameters
checkpoint_path: ???
patch_size: 32
context_length: 1000
num_samples: 100

# Evaluation parameters
batch_size: 256
min_batch_size: 1
device: cuda

# Metrics configuration (same as default eval config)
metrics:
  - _target_: gluonts.ev.metrics.MSE
  - _target_: uni2ts.eval_util.metrics.MedianMSE
  - _target_: gluonts.ev.metrics.MAE
  - _target_: gluonts.ev.metrics.MASE
  - _target_: gluonts.ev.metrics.MAPE
  - _target_: gluonts.ev.metrics.SMAPE
  - _target_: gluonts.ev.metrics.MSIS
  - _target_: gluonts.ev.metrics.RMSE
  - _target_: gluonts.ev.metrics.NRMSE
  - _target_: gluonts.ev.metrics.ND
  - _target_: gluonts.ev.metrics.MeanWeightedSumQuantileLoss
    quantile_levels: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

hydra:
  run:
    dir: outputs/eval_embedding_precond/${now:%Y%m%d_%H%M%S}
  job:
    chdir: true
